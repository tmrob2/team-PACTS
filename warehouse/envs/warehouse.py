from optparse import Option
from gym import spaces
import numpy as np
from typing import Optional, List, Tuple
from gym.utils.renderer import Renderer
import json
import gym
import random

class Warehouse(gym.Env):
    metadata = {"render_modes": ["human", "rgb_array", "single_rgb_array"], "render_fps": 4}

    def __init__(
        self, 
        initial_agent_loc: List,
        feedpoints: List[Tuple],
        nagents: int = 1, 
        render_mode: Optional[str] = None, 
        xsize: int=20, 
        ysize: int=20
        ):
        assert render_mode is None or render_mode in self.metadata["render_modes"]
        self.render_mode = render_mode

        self.xsize = xsize # the width of a grid
        self.ysize = ysize # the height of a grid
        self.window_size = 512 # the size of the pygame window
        self.nagents = nagents
        self.feedpoints = feedpoints

        self.state_mapping = {} # this will be required to interpret the scheduler
        # as a return from MOTAP
        self.reverse_state_mapping = {}

        self.initial_locations = initial_agent_loc # this is a list of the initial
        self.agent_obs = [{"a": aloc, "c": 0, "r": None} for aloc in initial_agent_loc]
        # agent locations

        # Observations are dictionaries with the agent's and target's locatoin
        # each location is encoded as an element  {0,..., size}^2 i.e. MultiDiscrete([size,size])

        self.observation_space = spaces.Dict({i:spaces.Dict({
            "a": spaces.Box(np.array([0, 0]), np.array([xsize - 1, ysize -1]), shape=(2,), dtype=int),
            "c": spaces.Discrete(2),
        }) for i in range(nagents)}) # r could also be none

        # use rust to determine the rack placement?
        # or just emulate the rack placement in the rust lib I don't think there
        # is any point in creating overlapping functions
        #self._rack_positions = dp_warehouse.place_racks(size, size) # is a set

        # there are four actions, corresponding to "right", "up", "left", "down"
        self.action_space = spaces.Discrete(6)

        """
        The following dictionary maps abstract actions from self.action_space to 
        the directions we will walk in if that action is taken
        I.e. 0 corresponds to right, so on..
        """
        self._action_to_direction = {
            0: np.array([1, 0]),
            1: np.array([0, 1]),
            2: np.array([-1, 0]),
            3: np.array([0, -1])
        }

        """
        If human rendering is used, "self.window" will be a reference to the window that we draw to
        'self.clock' will be a clock that is used to ensure that the environment is rendered at the
        correct framerate in human-mode.
        """
        if self.render_mode == "human":
            import pygame

            pygame.init()
            pygame.display.init()
            self.window = pygame.display.set_mode((self.window_size, self.window_size))
            self.clock = pygame.time.Clock()

        # the following line uses the util class Renderer to gather a collection of frames
        # using a method that computes a single frame. We will define _render_frame below
        self.renderer = Renderer(self.render_mode, self._render_frame)

        self.racks = set([])
        self.agent_rack_position = {i: None for i in range(nagents)}

    def label(self):
        """
        Because our MDPs are labelled MDPs we also need to include a labelling for each state.
        Now the labelling requires some conversion because the word generated by the grid is 
        actually its state, and this required mapping to the alphabet        
        """
        pass
    
    def reset(self, seed=None, options=None):
        super().reset(seed=seed)

        self.agent_locations = self.initial_locations

        self.renderer.reset()
        self.renderer.render_step()

        observations = {}
        # for each agent return the observation
        for i, agent in enumerate(self.initial_locations):
            observations[i] = {"a": agent, "c": 0}
            self.agent_rack_position[i] = None

        return observations

    
    def step(self, action: List): # action list will come directly from a policy 
        # the current state is self.state
        direction = self._action_to_direction[action]
        observations = {}
        rewards = []
        dones = []

        for i in range(self.nagents):
            # this is the action which corresponds to the agent
            v = []

            agent_obs_i = self.agent_obs[i]
            if action[i] in [0, 1, 2, 3]:
                # this is a directional movement, 
                # agents can move freely if they're not carrying anything
                # If an agent is carrying a rack then it operates within
                # corridors
                # is the agent carrying something
                carrying = agent_obs_i["c"]
                # The agent is not carrying something
                direction = self._action_to_direction[action[i]]
                agent_loc = agent_obs_i["a"]
                new_loc = np.clip(agent_loc + direction, 9, self.xsize-1)
                if carrying == 0:
                    # the agent is free to move in any direction
                    new_obs = {"a": new_loc, "c": carrying, "r": agent_obs_i["r"]}
                    # now we need to determine the word
                    word = ""
                    v.append((new_obs, 1.0, word))
                # the agent is carrying something
                else:
                    # if the new direction is not in racks then the agent may
                    # move to this new direction

                    # define two situations 
                    
                    if agent_obs_i["a"] in self.racks:
                        if new_loc in self.racks:
                            # then the agent may not move
                            new_obs = agent_obs_i
                            word = "" # the word is the current word as the state will not change
                            v.append((new_obs, 1.0, word))
                        else:
                            # the agent may freely move to the new position
                            #
                            # but there are two scenarios now
                            # 1. A failure scenario
                            # 2. A success scenario
                            # The agent succeeds in moving the rack to the new position
                            succ_obs = {"a": new_loc, "c": carrying, "r": new_loc}
                            # the agent fails to move the rack to the new position
                            # effectively dropping the rack
                            word_succ = ""
                            fail_obs = {"a": new_loc, "c": 0, "r": agent_obs_i["r"]}
                            word_fail = ""
                            v.append((succ_obs, 0.99, word_succ))
                            v.append((fail_obs, 0.01, word_fail))
                    else:
                        succ_obs = {"a": new_loc, "c": carrying, "r": new_loc}
                        # the agent fails to move the rack to the new position
                        # effectively dropping the rack
                        word_succ = ""
                        fail_obs = {"a": new_loc, "c": 0, "r": agent_obs_i["r"]}
                        word_fail = ""
                        v.append((succ_obs, 0.99, word_succ))
                        v.append((fail_obs, 0.01, word_fail))
            elif action == 4:
                # pickup a rack if the agent and rack coincide or the agent is
                # at a rack position
                if agent_obs_i["c"] == 0:
                    # if the agent is in a rack position then it may carry a rack
                    if agent_obs_i["a"] in self.racks:
                        new_obs = {"a": agent_obs_i["a"], "c": 1, "r": agent_obs_i["a"]}
                        word = ""
                        v.push((new_obs, 1.0, word))
                    else:
                        new_obs = agent_obs_i
                        word = ""
                        v.push((new_obs, 1.0, word))
                else:
                    # The agent is already carrying something and therefore canno pickup 
                    # something else
                    new_obs = agent_obs_i
                    word = ""
                    v.push((new_obs, 1.0, word))
            elif action == 5:
                # drop a rack anywhere if the agent is carrying a rack
                if agent_obs_i["c"] == 1:
                    new_obs = {"a": agent_obs_i["a"], "c": 0, "r": None}
                    word = ""
                    v.push((new_obs, 1.0, word))
                else:
                    # The agent is not carrying anything and therefore cannot drop anything
                    new_obs = agent_obs_i
                    word = ""
                    v.push((new_obs, 1.0, word))
            else:
                raise("Action not registered")

            # at this point we need to choose a new state based on the probs
            # in v
            probs = map(lambda x: x[1], v)
            indices = list(range(len(v)))
            ind = random.choices(indices, probs) 
            # with ind return the observation, reward, and done
            observations[i] = {"a": v[ind][0]["a"], "c": v[ind][0]["c"]}
            self.agent_rack_position[i] = v[ind][0]["r"]
            rewards.append(-1)
            dones.append(False)
            self.renderer.render_step()
            info = {"prob": v[ind][1], "word": v[ind][2]}

        return observations, rewards, dones, info


    def render(self):
        return self.renderer.get_renders()

    def _render_frame(self, mode: str):
        # This will be the function called by the renderer to collect a single frame
        assert mode is not None

        import pygame # avoid global pygame dependency

        canvas = pygame.Surface((self.window_size, self.window_size))
        canvas.fill((255, 255, 255)) # make a white canvas
        pix_square_size = (
            # divide the canvas into square sizes corresponding to the grid
            # clearly here it is easier if the grid is square
            self.window_size / self.xsize
        )

        # For each of the feed locations draw a green square
        for floc in self.feedpoints:
            pygame.draw.rect(
                canvas,
                (255, 0 ,0),
                pygame.Rect(
                    pix_square_size * floc,
                    (pix_square_size, pix_square_size)
                ),
            )
        
        # draw each of the agents as a circle
        for ag in range(self.nagents):
            pygame.draw.circle(
                canvas,
                (0, 255, 0),
                (self.agent_obs[ag]["a"] + 0.5) * pix_square_size,
                pix_square_size / 3
            )
        
        # Add some grid lines
        for x in range(self.xsize + 1):
            pygame.draw.line(
                canvas,
                0,
                (0, pix_square_size * x),
                (self.window_size, pix_square_size * x),
                width=3,
            )
            pygame.draw.line(
                canvas,
                0,
                (pix_square_size * x, 0),
                (pix_square_size * x, self.window_size),
                width=3,
            )
        if mode == "human":
            assert self.window is not None
            # The following line copies our drawings from `canvas` to the visible window
            self.window.blit(canvas, canvas.get_rect())
            pygame.event.pump()
            pygame.display.update()

            # We need to ensure that human-rendering occurs at the predefined framerate.
            # The following line will automatically add a delay to keep the framerate stable.
            self.clock.tick(self.metadata["render_fps"])
        else:  # rgb_array or single_rgb_array
            return np.transpose(
                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)
            )

    def close(self):
        if self.window is not None:
            import pygame

            pygame.display.quit()
            pygame.quit()
            

    

        

